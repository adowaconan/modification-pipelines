{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['64chlocs.elp', 'label_extraction.npy', 'label_extraction.pkl', 'logistic_model.pkl', 'pineline 13.csv', 'pipe line 10', 'pipe line 10.csv', 'pipeline 13.pickle', 's5d2_final.edf', 's5d2_final_annotations.txt', 's6n2_final.edf', 's6n2_final_annotations.txt', 'single subject prediction.p', 'single subject testing.p', 'single subject.p', 'Sleep Stage Scoring Criteria.docx', 'spindle training.p', 'suj10_d1final.edf', 'suj10_d1final_annotations.txt', 'suj10_d2final.edf', 'suj10_d2final_annotations.txt', 'suj13_l2nap_day2 edited.edf', 'suj13_l2nap_day2 edited1.edf', 'suj13_l2nap_day2 edited1_annotations.txt', 'suj13_l2nap_day2 edited_annotations.txt', 'suj13_l2nap_day2 edited_C3.txt', 'suj13_l2nap_day2 edited_C4.txt', 'suj13_l2nap_day2 edited_F3.txt', 'suj13_l2nap_day2 edited_F4.txt', 'suj13_l2nap_day2 edited_O1.txt', 'suj13_l2nap_day2 edited_O2.txt', 'suj5_d1final.edf', 'suj5_d1final_annotations.txt', 'suj6_d1final.edf', 'suj6_d1final_annotations.txt', 'suj8_d1final.edf', 'suj8_d1final_annotations.txt', 'suj8_d2final.edf', 'suj8_d2final_annotations.txt', 'suj9_d1final.edf', 'suj9_d1final_annotations.txt', 'suj9_d2final.edf', 'suj9_d2final_annotations.txt', 'testing-montage-2.mtg', 'Training Data Frame', 'training data.p']\n"
     ]
    }
   ],
   "source": [
    "import eegPinelineDesign\n",
    "import numpy as np\n",
    "import random\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import scipy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA,FastICA\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from scipy.fftpack import fft,ifft\n",
    "import math\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "from scipy.signal import spectrogram,find_peaks_cwt,butter, lfilter\n",
    "from mne.preprocessing.ica import ICA\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.cross_validation import train_test_split,ShuffleSplit\n",
    "from sklearn.preprocessing import label_binarize,scale\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import label_binarize,StandardScaler\n",
    "\n",
    "\n",
    "eegPinelineDesign.change_file_directory('C:/Users/ning/Downloads/training set')\n",
    "EDFfiles, Annotationfiles = eegPinelineDesign.split_type_of_files()\n",
    "from eegPinelineDesign import CenterAtPeakOfWindow,Threshold_test,spindle_overlapping_test,used_windows_check,cut_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=500000000.0, multi_class='ovr',\n",
       "          n_jobs=-1, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=1e-08, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('training data.p','rb') as handle:\n",
    "    result=pickle.load(handle)\n",
    "    \n",
    "channelList=['F3','F4','C3','C4','O1','O2']\n",
    "X = [];Y=[]\n",
    "for num, EDFfileName in enumerate(EDFfiles):\n",
    "    if EDFfileName == 'suj13_l2nap_day2 edited.edf' or EDFfileName =='suj13_l2nap_day2 edited1.edf':\n",
    "        pass\n",
    "    else:\n",
    "        file_to_read,fileName=eegPinelineDesign.pick_sample_file(EDFfiles,n=num)\n",
    "\n",
    "\n",
    "        for names in channelList:\n",
    "            for item in result['spindle'][fileName][names]:\n",
    "                if item.shape[1] == 3000:\n",
    "\n",
    "                    X.append(item[0,:])\n",
    "                    Y.append(1)\n",
    "            for item in result['non spindle'][fileName][names]:\n",
    "                if item.shape[1] == 3000:\n",
    "                    X.append(item[0,:])\n",
    "                    Y.append(0)\n",
    "\n",
    "X=np.array(X);Y=np.array(Y)\n",
    "\n",
    "idx=np.arange(X.shape[0])\n",
    "GG=np.random.choice(tuple(idx),len(idx),replace=False)\n",
    "def shuffle(x):\n",
    "    return sorted(x, key=lambda k: random.random())\n",
    "GG = shuffle(shuffle(shuffle(shuffle(GG))))\n",
    "XX=[];YY=[]\n",
    "for idxx in GG:\n",
    "    XX.append(X[idxx])\n",
    "    YY.append(Y[idxx])\n",
    "    \n",
    "from sklearn.preprocessing import normalize\n",
    "normal_X = normalize(XX)\n",
    "\n",
    "clf =LogisticRegression(penalty='l2',C=.1,tol=10e-9,fit_intercept=True,solver='liblinear',\n",
    "                                             max_iter=5e8,multi_class='ovr',n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(normal_X,YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting edf Parameters from suj10_d1final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3601999  =      0.000 ...  3601.999 secs...\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    2, 7, 4, 4, 2\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Band-pass filtering from 11 - 16 Hz\n",
      "Extracting edf Parameters from suj10_d1final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3601999  =      0.000 ...  3601.999 secs...\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    2, 7, 4, 4, 2\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Band-pass filtering from 8 - 12 Hz\n",
      "Extracting edf Parameters from suj10_d1final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3601999  =      0.000 ...  3601.999 secs...\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    2, 7, 4, 4, 2\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Band-pass filtering from 11 - 16 Hz\n",
      "Extracting edf Parameters from suj10_d1final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3601999  =      0.000 ...  3601.999 secs...\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    2, 7, 4, 4, 2\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Band-pass filtering from 30 - 40 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RawEDF  |  suj10_d1final.edf, n_channels x n_times : 6 x 3602000 (3602.0 sec)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num=2\n",
    "file_to_read,fileName=eegPinelineDesign.pick_sample_file(EDFfiles,n=num)\n",
    "channelList = ['F3','F4','C3','C4','O1','O2','ROC','LOC']\n",
    "raw_filter = eegPinelineDesign.load_data(file_to_read,channelList,11, 16)#spindle pass\n",
    "raw_alpha=eegPinelineDesign.load_data(file_to_read,channelList,8, 12)#alpha pass\n",
    "raw_spindle=eegPinelineDesign.load_data(file_to_read,channelList,11, 16)#spindle pass\n",
    "raw_muscle=eegPinelineDesign.load_data(file_to_read,channelList,30, 40)#\n",
    "channelList = ['F3','F4','C3','C4','O1','O2']\n",
    "raw_filter.pick_channels(channelList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[306.56, 308.603, 309.972, 314.434, 321.003, 337.655, 372.71, 386.15, 442.946, 446.895, 450.7, 458.861, 465.311, 481.595, 542.337, 554.0, 571.428, 624.319, 625.847, 666.74, 675.803, 733.183, 760.274, 764.011, 766.605, 785.35, 792.313, 840.669, 842.973, 847.159, 850.371, 899.037, 908.949, 917.387, 970.358, 988.0055482, 1035.83, 1047.203, 1049.204, 1052.14, 1064.356, 1081.982, 1084.917, 1105.258, 1164.727, 1168.913, 1173.869, 1181.438, 1185.299, 1231.585, 1235.797, 1245.591, 1248.513, 1269.18, 1296.231, 1298.746, 1300.536, 1332.55, 1346.319, 1359.022, 1361.958, 1363.577, 1367.157, 1368.197, 1400.488, 1403.028, 1410.137, 1412.203, 1431.278, 1469.979, 1480.031, 1486.336, 1491.72, 1519.956, 1524.682, 1531.001, 1533.87, 1536.279, 1538.293, 1543.612, 1546.231, 1574.48, 1579.311, 1582.497, 1621.001, 1643.755, 1659.939, 1663.98, 1671.733, 1685.674, 1800.66, 1802.134, 1850.214, 1862.417, 1879.148, 1928.648, 1930.533, 1957.27, 1960.728, 1986.567, 2016.909, 2081.118, 2108.262, 2139.712, 2177.437, 2182.49, 2191.561, 2195.3, 2197.959, 2235.528, 2243.874, 2255.445, 2275.493, 2284.234, 2313.812, 2349.96, 2363.847, 3107.632, 3263.009, 3266.103, 3305.063, 3308.999, 3310.131, 3311.105, 3321.254, 3349.875, 3356.454, 3383.742, 3395.976, 3458.433, 3465.265, 3468.556, 3485.038, 3493.871, 3505.859, 3525.131, 3542.098, 3551.971, 3562.489, 3566.491]\n"
     ]
    }
   ],
   "source": [
    "annotation_to_read = [x for x in Annotationfiles if fileName in x]\n",
    "file = pd.read_csv(annotation_to_read[0])\n",
    "labelFind = re.compile('spindle',eegPinelineDesign.re.IGNORECASE)\n",
    "spindles=[]# take existed annotations\n",
    "for row in file.iterrows():\n",
    "    currentEvent = row[1][-1]\n",
    "    if labelFind.search(currentEvent):\n",
    "        spindles.append(row[1][0])# time of marker\n",
    "print(spindles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[3.5, 6.5] 5 0\n",
      "[3.5, 6.5] 5 0\n",
      "[3.5, 6.5] 5 0\n",
      "[3.5, 6.5] 5 [0]\n",
      "[3.5, 6.5] 5 [0]\n",
      "[3.5, 6.5] 5 0\n",
      "6\n",
      "[4.5, 7.5] 6 0\n",
      "[4.5, 7.5] 6 [0]\n",
      "[4.5, 7.5] 6 0\n",
      "[4.5, 7.5] 6 [0]\n",
      "[4.5, 7.5] 6 [0]\n",
      "[4.5, 7.5] 6 0\n",
      "7\n",
      "[5.5, 8.5] 7 0\n",
      "[5.5, 8.5] 7 0\n",
      "[5.5, 8.5] 7 0\n",
      "[5.5, 8.5] 7 [0]\n",
      "[5.5, 8.5] 7 [0]\n",
      "[5.5, 8.5] 7 0\n",
      "8\n",
      "[6.5, 9.5] 8 0\n",
      "[6.5, 9.5] 8 [0]\n",
      "[6.5, 9.5] 8 0\n",
      "[6.5, 9.5] 8 [0]\n",
      "[6.5, 9.5] 8 [0]\n",
      "[6.5, 9.5] 8 0\n",
      "9\n",
      "[7.5, 10.5] 9 0\n",
      "[7.5, 10.5] 9 [0]\n",
      "[7.5, 10.5] 9 0\n",
      "[7.5, 10.5] 9 [0]\n",
      "[7.5, 10.5] 10.459 [1]\n",
      "[7.5, 10.5] 9 0\n",
      "10\n",
      "[8.5, 11.5] 10 0\n",
      "[8.5, 11.5] 10 [0]\n",
      "[8.5, 11.5] 10 0\n",
      "[8.5, 11.5] 10 [0]\n",
      "[8.5, 11.5] 10 [0]\n",
      "[8.5, 11.5] 10 0\n",
      "11\n",
      "[9.5, 12.5] 11 0\n",
      "[9.5, 12.5] 11 [0]\n",
      "[9.5, 12.5] 11 0\n",
      "[9.5, 12.5] 11 [0]\n",
      "[9.5, 12.5] 11 [0]\n",
      "[9.5, 12.5] 11 0\n",
      "12\n",
      "[10.5, 13.5] 12 0\n",
      "[10.5, 13.5] 10.529 [1]\n",
      "[10.5, 13.5] 12 0\n"
     ]
    }
   ],
   "source": [
    "TimePoint = 0+5;cnt = 0\n",
    "time_label={};resolution = 1\n",
    "for names in channelList:\n",
    "    time_label[names]=[]\n",
    "while raw_filter.last_samp/1000 - TimePoint > 5:\n",
    "    if any(abs(np.array(spindles) - TimePoint) < 1):\n",
    "        print(TimePoint,np.array(spindles)[np.argmin(abs(np.array(spindles)-TimePoint))])\n",
    "    else:\n",
    "        print(TimePoint)\n",
    "    for ii,names in enumerate(channelList):\n",
    "        if Threshold_test(TimePoint,raw_alpha,raw_spindle,raw_muscle,ii):\n",
    "            tempSegment,timeSpan=cut_segments(raw_filter,TimePoint,ii,windowsize = 1.5)\n",
    "            normalziedSegment = normalize(tempSegment[0,:3000])#key step!!!\n",
    "            predictedLabel = clf.predict(normalziedSegment)\n",
    "            if predictedLabel == 1:\n",
    "                # only find the peak of spindles, if not, why bother\n",
    "                peakXval = eegPinelineDesign.CenterAtPeakOfWindow(TimePoint,1.5,raw_filter,ii)\n",
    "                time_label[names].append([[TimePoint-1.5,TimePoint+1.5],peakXval,predictedLabel])\n",
    "                print([TimePoint-1.5,TimePoint+1.5],peakXval,predictedLabel)\n",
    "            else:\n",
    "                time_label[names].append([[TimePoint-1.5, TimePoint+1.5],TimePoint,predictedLabel])\n",
    "                print([TimePoint-1.5,TimePoint+1.5],TimePoint,predictedLabel)\n",
    "        else:\n",
    "            time_label[names].append([[TimePoint-1.5, TimePoint+1.5],TimePoint,0])\n",
    "            print([TimePoint-1.5,TimePoint+1.5],TimePoint,0)\n",
    "    TimePoint += resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
