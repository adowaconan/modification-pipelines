{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import eegPinelineDesign\n",
    "import numpy as np\n",
    "import random\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import scipy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA,FastICA\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from scipy.fftpack import fft,ifft\n",
    "import math\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "from scipy.signal import spectrogram,find_peaks_cwt,butter, lfilter\n",
    "from mne.preprocessing.ica import ICA\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.cross_validation import train_test_split,ShuffleSplit\n",
    "from sklearn.preprocessing import label_binarize,scale\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import label_binarize,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EDFfiles, Annotationfiles = eegPinelineDesign.split_type_of_files()\n",
    "\n",
    "from eegPinelineDesign import CenterAtPeakOfWindow,Threshold_test,spindle_overlapping_test,used_windows_check,cut_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('single subject.p','rb') as handle:\n",
    "    result = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['nonspindle time', 'spindle', 'non spindle', 'spindle time'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['suj10_d1final'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['spindle'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileName=list(result['spindle'].keys())[0]\n",
    "channelList=['F3','F4','C3','C4','O1','O2']\n",
    "X = [];Y=[]\n",
    "for names in channelList:\n",
    "    for item in result['spindle'][fileName][names]:\n",
    "        if item.shape[1] == 3000:\n",
    "\n",
    "            X.append(item[0,:])\n",
    "            Y.append(1)\n",
    "    for item in result['non spindle'][fileName][names]:\n",
    "        if item.shape[1] == 3000:\n",
    "            X.append(item[0,:])\n",
    "            Y.append(0)\n",
    "\n",
    "X=np.array(X);Y=np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1451, 3000), (1451,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic,1 fold, 80/20 train/test slipt\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90       136\n",
      "          1       0.93      0.89      0.91       155\n",
      "\n",
      "avg / total       0.90      0.90      0.90       291\n",
      "\n",
      "within training data set 0.924137931034\n"
     ]
    }
   ],
   "source": [
    "idx=np.arange(X.shape[0])\n",
    "GG=np.random.choice(tuple(idx),len(idx),replace=False)\n",
    "def shuffle(x):\n",
    "    return sorted(x, key=lambda k: random.random())\n",
    "GG = shuffle(shuffle(shuffle(shuffle(GG))))\n",
    "XX=[];YY=[]\n",
    "for idxx in GG:\n",
    "    XX.append(X[idxx])\n",
    "    YY.append(Y[idxx])\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "normal_X = normalize(XX)\n",
    "X_train, X_test, y_train, y_test = train_test_split(normal_X, YY, test_size=0.20)\n",
    "\n",
    "#print(y_train)\n",
    "\n",
    "clf =LogisticRegression(penalty='l2',C=.1,tol=10e-9,fit_intercept=True,solver='liblinear',\n",
    "                                             max_iter=10e7,multi_class='ovr',n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "print('logistic,1 fold, 80/20 train/test slipt')\n",
    "print(classification_report(clf.predict(X_test),y_test))\n",
    "print('within training data set',clf.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting edf Parameters from suj10_d1final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3601999  =      0.000 ...  3601.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    2, 7, 4, 4, 2\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "Band-pass filtering from 11 - 16 Hz\n",
      "Extracting edf Parameters from suj10_d1final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3601999  =      0.000 ...  3601.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    2, 7, 4, 4, 2\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "Band-pass filtering from 8 - 12 Hz\n",
      "Extracting edf Parameters from suj10_d1final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3601999  =      0.000 ...  3601.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    2, 7, 4, 4, 2\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "Band-pass filtering from 11 - 16 Hz\n",
      "Extracting edf Parameters from suj10_d1final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3601999  =      0.000 ...  3601.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    2, 7, 4, 4, 2\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "Band-pass filtering from 30 - 40 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RawEDF  |  n_channels x n_times : 6 x 3602000>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num=2\n",
    "file_to_read,fileName=eegPinelineDesign.pick_sample_file(EDFfiles,n=num)\n",
    "channelList = ['F3','F4','C3','C4','O1','O2','ROC','LOC']\n",
    "raw_filter = eegPinelineDesign.load_data(file_to_read,channelList,11, 16)#spindle pass\n",
    "raw_alpha=eegPinelineDesign.load_data(file_to_read,channelList,8, 12)#alpha pass\n",
    "raw_spindle=eegPinelineDesign.load_data(file_to_read,channelList,11, 16)#spindle pass\n",
    "raw_muscle=eegPinelineDesign.load_data(file_to_read,channelList,30, 40)#\n",
    "channelList = ['F3','F4','C3','C4','O1','O2']\n",
    "raw_filter.pick_channels(channelList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_label={};resolution = 0.1\n",
    "for names in channelList:\n",
    "    time_label[names]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "55.00000000000051\n",
      "104.99999999999831\n",
      "154.99999999999548\n",
      "204.99999999999264\n",
      "254.9999999999898\n",
      "305.00000000000085\n",
      "355.0000000000122\n",
      "405.0000000000236\n",
      "455.00000000003496\n",
      "505.0000000000463\n",
      "555.0000000000576\n",
      "605.000000000069\n",
      "655.0000000000804\n",
      "705.0000000000917\n",
      "755.0000000001031\n",
      "805.0000000001145\n",
      "855.0000000001259\n",
      "905.0000000001372\n",
      "955.0000000001486\n",
      "1005.00000000016\n",
      "1055.000000000136\n",
      "1105.0000000000905\n",
      "1155.000000000045\n",
      "1204.9999999999995\n",
      "1254.999999999954\n",
      "1304.9999999999086\n",
      "1354.9999999998631\n",
      "1404.9999999998176\n",
      "1454.9999999997722\n",
      "1504.9999999997267\n",
      "1554.9999999996812\n",
      "1604.9999999996357\n",
      "1654.9999999995903\n",
      "1704.9999999995448\n",
      "1754.9999999994993\n",
      "1804.9999999994538\n",
      "1854.9999999994084\n",
      "1904.999999999363\n",
      "1954.9999999993174\n",
      "2004.999999999272\n",
      "2054.9999999992265\n",
      "2104.999999999181\n",
      "2154.9999999991355\n",
      "2204.99999999909\n",
      "2254.9999999990446\n",
      "2304.999999998999\n",
      "2354.9999999989536\n",
      "2404.999999998908\n",
      "2454.9999999988627\n",
      "2504.999999998817\n",
      "2554.9999999987717\n",
      "2604.9999999987263\n",
      "2654.999999998681\n",
      "2704.9999999986353\n",
      "2754.99999999859\n",
      "2804.9999999985444\n",
      "2854.999999998499\n",
      "2904.9999999984534\n",
      "2954.999999998408\n",
      "3004.9999999983625\n",
      "3054.999999998317\n",
      "3104.9999999982715\n",
      "3154.999999998226\n",
      "3204.9999999981806\n",
      "3254.999999998135\n",
      "3304.9999999980896\n",
      "3354.999999998044\n",
      "3404.9999999979987\n",
      "3454.999999997953\n",
      "3504.9999999979077\n",
      "3554.9999999978622\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "centerPoint = 0+5;cnt = 0\n",
    "while raw_filter.last_samp/1000 - centerPoint > 1.5:\n",
    "    if (cnt % 500) == 0:\n",
    "        print(centerPoint)\n",
    "    for ii,names in enumerate(channelList):\n",
    "    \n",
    "        if Threshold_test(centerPoint,raw_alpha,raw_spindle,raw_muscle,ii):\n",
    "            tempSegment,timeSpan=cut_segments(raw_filter,centerPoint,ii,windowsize = 1.5)\n",
    "            normalziedSegment = normalize(tempSegment[0,:3000])#key step!!!\n",
    "            predictedLabel = clf.predict(normalziedSegment)\n",
    "            time_label[names].append([centerPoint,predictedLabel])\n",
    "        else:\n",
    "            time_label[names].append([centerPoint,0])\n",
    "\n",
    "    centerPoint += resolution;cnt += 1\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('single subject testing.p','wb') as handle:\n",
    "    pickle.dump(time_label,handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for ii, names in enumerate(channelList):\n",
    "    lengths.append(len(time_label[names]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_label_matrix = np.zeros([7,np.min(lengths)])\n",
    "time_label_matrix[0,:]=np.array(time_label['C4'])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ii, names in enumerate(channelList):\n",
    "    time_label_matrix[ii+1,:] = np.array(time_label[names])[:min(lengths),1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    64816078.499977\n",
       "1        1732.000000\n",
       "2        2089.000000\n",
       "3        1891.000000\n",
       "4        2085.000000\n",
       "5        2281.000000\n",
       "6        1973.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(time_label_matrix.T).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
