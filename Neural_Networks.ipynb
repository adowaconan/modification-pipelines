{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable\tDefinition\n",
    "\n",
    "X:\tInput dataset matrix where each row is a training example\n",
    "\n",
    "y:\tOutput dataset matrix where each row is a training example\n",
    "\n",
    "l0:\tFirst Layer of the Network, specified by the input data\n",
    "\n",
    "l1:\tSecond Layer of the Network, otherwise known as the hidden layer\n",
    "\n",
    "l2:\tFinal Layer of the Network, which is our hypothesis, and should approximate the correct answer as we train.\n",
    "\n",
    "syn0:\tFirst layer of weights, Synapse 0, connecting l0 to l1.\n",
    "\n",
    "syn1:\tSecond layer of weights, Synapse 1 connecting l1 to l2.\n",
    "\n",
    "l2_error:\tThis is the amount that the neural network \"missed\".\n",
    "\n",
    "l2_delta:\tThis is the error of the network scaled by the confidence. It's almost identical to the error except that very confident errors are muted.\n",
    "\n",
    "l1_error:\tWeighting l2_delta by the weights in syn1, we can calculate the error in the middle/hidden layer.\n",
    "\n",
    "l1_delta:\tThis is the l1 error of the network scaled by the confidence. Again, it's almost identical to the l1_error except that confident errors are muted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([ [0,0,1],[0,1,1],[1,0,1],[1,1,1] ])\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "syn0 = 2*np.random.random((3,4)) - 1\n",
    "syn1 = 2*np.random.random((4,1)) - 1\n",
    "for j in range(60000):\n",
    "    l1 = 1/(1+np.exp(-(np.dot(X,syn0))))\n",
    "    l2 = 1/(1+np.exp(-(np.dot(l1,syn1))))\n",
    "    l2_delta = (y - l2)*(l2*(1-l2))\n",
    "    l1_delta = l2_delta.dot(syn1.T) * (l1 * (1-l1))\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += X.T.dot(l1_delta)\n",
    "# this is a bit terse... let's break it aprat into a \n",
    "# few simple parts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.81573298 -0.99963235  6.05225847  8.34641714]\n",
      " [ 8.0128032   4.05312365  6.05628932 -4.40227592]\n",
      " [ 0.21437067 -0.75308567 -0.60513427  0.59387988]]\n"
     ]
    }
   ],
   "source": [
    "print(syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -9.17300316]\n",
      " [ -1.72625688]\n",
      " [ 16.15361643]\n",
      " [-10.51794185]]\n"
     ]
    }
   ],
   "source": [
    "print(syn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# sigmoid function\n",
    "def nonlin(x,deriv=False):\n",
    "    if(deriv == True):\n",
    "        return(x*(1-x))\n",
    "    return(1/(1+np.exp(-x)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input dataset\n",
    "X = np.array([  [0,0,1],\n",
    "              [0,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1] ])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# output dataset\n",
    "y = np.array([[0,0,1,1]]).T\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seed random numbers to make calculation\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize weights randomly with mean 0\n",
    "syn0 = 2 * np.random.random((3,1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output After Training: [[ 0.00966449]\n",
      " [ 0.00786506]\n",
      " [ 0.99358898]\n",
      " [ 0.99211957]]\n"
     ]
    }
   ],
   "source": [
    "for iter in range(10000):\n",
    "    #forward propagation\n",
    "    l0 = X\n",
    "    l1 = nonlin(np.dot(l0,syn0))\n",
    "    \n",
    "    # how much did we miss?\n",
    "    l1_error = y - l1\n",
    "    \n",
    "    # multiply how much we missed by the #\n",
    "    # slope of sigmoid at the values in l1\n",
    "    l1_delta = l1_error * nonlin(l1,True)\n",
    "    \n",
    "    # update weights\n",
    "    syn0 += np.dot(l0.T,l1_delta)\n",
    "\n",
    "    \n",
    "print(\"Output After Training:\",l1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.16595599,  0.44064899, -0.99977125, -0.39533485],\n",
       "        [-0.70648822, -0.81532281, -0.62747958, -0.30887855],\n",
       "        [-0.20646505,  0.07763347, -0.16161097,  0.370439  ]]),\n",
       " array([[-0.5910955 ],\n",
       "        [ 0.75623487],\n",
       "        [-0.94522481],\n",
       "        [ 0.34093502]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 layer neural network\n",
    "import numpy as np\n",
    "\n",
    "def nolin(x,deriv=False):\n",
    "    if(deriv == True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "X = np.array([  [0,0,1],\n",
    "              [0,1,1],\n",
    "              [1,0,1],\n",
    "              [1,1,1] ])\n",
    "\n",
    "y = np.array([[0,0,1,1]]).T\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# randomly initialize our weights with mean 0\n",
    "syn0 = 2* np.random.random((3,4))-1\n",
    "syn1 = 2* np.random.random((4,1))-1\n",
    "syn0,syn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error0.468534325458\n",
      "Error0.0050024267254\n",
      "Error0.00345440546153\n",
      "Error0.00278655701967\n",
      "Error0.00239411550552\n",
      "Error0.00212888526823\n"
     ]
    }
   ],
   "source": [
    "for j in range(60000):\n",
    "    #feed forward through layers 0,1 and 2\n",
    "    l0 = X\n",
    "    l1 = nonlin(np.dot(l0,syn0))\n",
    "    l2 = nonlin(np.dot(l1,syn1))\n",
    "    \n",
    "    # how much did we miss?\n",
    "    \n",
    "    l2_error = y - l2\n",
    "    \n",
    "    if (j% 10000) == 0:\n",
    "        print(\"Error\" + str(np.mean(np.abs(l2_error))))\n",
    "        \n",
    "    # in what direction is the target value?\n",
    "    # were we reallly sure? if so, don't change too much\n",
    "    l2_delta = l2_error * nonlin(l2,deriv=True)\n",
    "    \n",
    "    # how much did each l1 value contribute to the \n",
    "    # l2 error (according to the weights)?\n",
    "    l1_error = l2_delta.dot(syn1.T)\n",
    "    \n",
    "    # in what direction is the target l1? \n",
    "    # were we really sure? if so,don't change too much\n",
    "    l1_delta = l1_error * nonlin(l1, deriv=True)\n",
    "    \n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += l0.T.dot(l1_delta)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# not relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "border = 2\n",
    "images_amount = 300\n",
    "row_amount = 10\n",
    "col_amount = 30\n",
    "image_height = 28\n",
    "image_width = 28\n",
    "\n",
    "\n",
    "all_filter_image = np.zeros((row_amount*image_height + border*row_amount,\n",
    "                             col_amount*image_width + border*col_amount))\n",
    "\n",
    "\n",
    "for filter_num in range(images_amount):\n",
    "    start_row = image_height*(filter_num / col_amount) +\\\n",
    "                (filter_num / col_amount + 1)*border\n",
    "\n",
    "    end_row = start_row + image_height\n",
    "\n",
    "    start_col = image_width*(filter_num % col_amount) +\\\n",
    "                (filter_num % col_amount + 1)*border\n",
    "\n",
    "    end_col = start_col + image_width\n",
    "\n",
    "    all_filter_image[start_row:end_row, start_col:end_col] = \\\n",
    "        all_filters[filter_num]\n",
    "\n",
    "    print(start_row, end_row, start_col, end_col)\n",
    "\n",
    "\n",
    "pyplot.imshow(all_filter_image)\n",
    "pyplot.axis('off')\n",
    "pyplot.set_cmap('spectral')\n",
    "pyplot.colorbar()\n",
    "#pyplot.savefig('repflds1.png')\n",
    "http://stackoverflow.com/questions/30290506/neural-network-receptive-field-visualization-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
