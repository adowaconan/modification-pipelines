{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\pandas\\__init__.py:7: DeprecationWarning: bad escape \\s\n",
      "  from pandas import hashtable, tslib, lib\n",
      "c:\\anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility\n",
      "  return f(*args, **kwds)\n",
      "c:\\anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility\n",
      "  return f(*args, **kwds)\n",
      "c:\\anaconda3\\lib\\site-packages\\ipykernel\\pylab\\config.py:66: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  inline backend.\"\"\"\n",
      "c:\\anaconda3\\lib\\site-packages\\ipykernel\\pylab\\config.py:71: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  'retina', 'jpeg', 'svg', 'pdf'.\"\"\")\n",
      "c:\\anaconda3\\lib\\site-packages\\ipykernel\\pylab\\config.py:85: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  use `figure_formats` instead)\"\"\")\n",
      "c:\\anaconda3\\lib\\site-packages\\ipykernel\\pylab\\config.py:95: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  \"\"\"\n",
      "c:\\anaconda3\\lib\\site-packages\\ipykernel\\pylab\\config.py:114: DeprecationWarning: metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "  \"\"\")\n",
      "c:\\anaconda3\\lib\\site-packages\\ipykernel\\pylab\\config.py:44: DeprecationWarning: InlineBackend._config_changed is deprecated: use @observe and @unobserve instead.\n",
      "  def _config_changed(self, name, old, new):\n",
      "c:\\anaconda3\\lib\\site-packages\\traitlets\\traitlets.py:770: DeprecationWarning: A parent of InlineBackend._config_changed has adopted the new @observe(change) API\n",
      "  clsname, change_or_name), DeprecationWarning)\n",
      "c:\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py:98: DeprecationWarning: DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "  def _formatters_default(self):\n",
      "c:\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n",
      "c:\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "c:\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "c:\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "c:\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n"
     ]
    }
   ],
   "source": [
    "import eegPinelineDesign\n",
    "import numpy as np\n",
    "import random\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import scipy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA,FastICA\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from scipy.fftpack import fft,ifft\n",
    "import math\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "from scipy.signal import spectrogram,find_peaks_cwt\n",
    "from mne.preprocessing.ica import ICA\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.cross_validation import train_test_split,ShuffleSplit\n",
    "from sklearn.preprocessing import label_binarize,scale\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import label_binarize,StandardScaler\n",
    "from nitime import algorithms as alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['64chlocs.elp', 'label_extraction.npy', 'label_extraction.pkl', 's5d2_final.edf', 's5d2_final_annotations.txt', 's6n2_final.edf', 's6n2_final_annotations.txt', 'Sleep Stage Scoring Criteria.docx', 'suj10_d1final.edf', 'suj10_d1final_annotations.txt', 'suj10_d2final.edf', 'suj10_d2final_annotations.txt', 'suj13_l2nap_day2 edited.edf', 'suj13_l2nap_day2 edited1.edf', 'suj13_l2nap_day2 edited1_annotations.txt', 'suj13_l2nap_day2 edited_annotations.txt', 'suj13_l2nap_day2 edited_C3.txt', 'suj13_l2nap_day2 edited_C4.txt', 'suj13_l2nap_day2 edited_F3.txt', 'suj13_l2nap_day2 edited_F4.txt', 'suj13_l2nap_day2 edited_O1.txt', 'suj13_l2nap_day2 edited_O2.txt', 'suj5_d1final.edf', 'suj5_d1final_annotations.txt', 'suj6_d1final.edf', 'suj6_d1final_annotations.txt', 'suj8_d1final.edf', 'suj8_d1final_annotations.txt', 'suj8_d2final.edf', 'suj8_d2final_annotations.txt', 'suj9_d1final.edf', 'suj9_d1final_annotations.txt', 'suj9_d2final.edf', 'suj9_d2final_annotations.txt', 'testing-montage-2.mtg', 'Training Data Frame']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py:92: DeprecationWarning: DisplayFormatter._ipython_display_formatter_default is deprecated: use @default decorator instead.\n",
      "  def _ipython_display_formatter_default(self):\n",
      "c:\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['s5d2_final.edf',\n",
       " 's6n2_final.edf',\n",
       " 'suj10_d1final.edf',\n",
       " 'suj10_d2final.edf',\n",
       " 'suj13_l2nap_day2 edited.edf',\n",
       " 'suj13_l2nap_day2 edited1.edf',\n",
       " 'suj5_d1final.edf',\n",
       " 'suj6_d1final.edf',\n",
       " 'suj8_d1final.edf',\n",
       " 'suj8_d2final.edf',\n",
       " 'suj9_d1final.edf',\n",
       " 'suj9_d2final.edf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eegPinelineDesign.change_file_directory('C:/Users/ning/Downloads/training set')\n",
    "EDFfiles, Annotationfiles = eegPinelineDesign.split_type_of_files()\n",
    "EDFfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting edf Parameters from s5d2_final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3383999  =      0.000 ...  3383.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    5, 6, 0, 0, 7\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 4 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "Low-pass filtering at 5e+02 Hz\n",
      "Low-pass filtering at 1e+02 Hz\n",
      "length of labels 113\n",
      "Extracting edf Parameters from s6n2_final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 2073999  =      0.000 ...  2073.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    2, 7, 4, 4, 2\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "Low-pass filtering at 5e+02 Hz\n",
      "Low-pass filtering at 1e+02 Hz\n",
      "length of labels 183\n",
      "Extracting edf Parameters from suj10_d1final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3601999  =      0.000 ...  3601.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    2, 7, 4, 4, 2\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "Low-pass filtering at 5e+02 Hz\n",
      "Low-pass filtering at 1e+02 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\mne\\filter.py:333: UserWarning: Attenuation at stop frequency 4.5Hz is only 17.2dB.\n",
      "  '%0.1fdB.' % (att_freq, att_db))\n",
      "c:\\anaconda3\\lib\\site-packages\\mne\\filter.py:333: UserWarning: Attenuation at stop frequency 8.0Hz is only 15.6dB.\n",
      "  '%0.1fdB.' % (att_freq, att_db))\n",
      "c:\\anaconda3\\lib\\site-packages\\mne\\filter.py:333: UserWarning: Attenuation at stop frequency 7.0Hz is only 15.6dB.\n",
      "  '%0.1fdB.' % (att_freq, att_db))\n",
      "c:\\anaconda3\\lib\\site-packages\\mne\\filter.py:333: UserWarning: Attenuation at stop frequency 13.5Hz is only 15.6dB.\n",
      "  '%0.1fdB.' % (att_freq, att_db))\n",
      "c:\\anaconda3\\lib\\site-packages\\mne\\filter.py:333: UserWarning: Attenuation at stop frequency 39.5Hz is only 16.9dB.\n",
      "  '%0.1fdB.' % (att_freq, att_db))\n",
      "c:\\anaconda3\\lib\\site-packages\\mne\\filter.py:333: UserWarning: Attenuation at stop frequency 4.5Hz is only 11.6dB.\n",
      "  '%0.1fdB.' % (att_freq, att_db))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of labels 304\n",
      "Extracting edf Parameters from suj10_d2final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3704999  =      0.000 ...  3704.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 3 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    1, 4, 6, 4, 4, 0\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 4 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "Low-pass filtering at 5e+02 Hz\n",
      "Low-pass filtering at 1e+02 Hz\n",
      "length of labels 429\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "skip this instance\n",
      "Extracting edf Parameters from suj5_d1final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3686999  =      0.000 ...  3686.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 1 artifact by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    7, 6, 6, 1\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "Low-pass filtering at 5e+02 Hz\n",
      "Low-pass filtering at 1e+02 Hz\n",
      "length of labels 552\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "Extracting edf Parameters from suj6_d1final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3560999  =      0.000 ...  3560.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 1 artifact by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    6, 7, 7, 6\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 2 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "Low-pass filtering at 5e+02 Hz\n",
      "Low-pass filtering at 1e+02 Hz\n",
      "length of labels 670\n",
      "Extracting edf Parameters from suj8_d1final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3582999  =      0.000 ...  3582.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    2, 5, 7, 7, 3\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 4 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "Low-pass filtering at 5e+02 Hz\n",
      "Low-pass filtering at 1e+02 Hz\n",
      "length of labels 789\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n",
      "Extracting edf Parameters from suj8_d2final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3563999  =      0.000 ...  3563.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 1 artifact by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    4, 4, 4, 6\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 2 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "Low-pass filtering at 5e+02 Hz\n",
      "Low-pass filtering at 1e+02 Hz\n",
      "length of labels 904\n",
      "Extracting edf Parameters from suj9_d1final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3605999  =      0.000 ...  3605.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    0, 7, 4, 4, 0\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "Low-pass filtering at 5e+02 Hz\n",
      "Low-pass filtering at 1e+02 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\mne\\filter.py:333: UserWarning: Attenuation at stop frequency 3.5Hz is only 8.9dB.\n",
      "  '%0.1fdB.' % (att_freq, att_db))\n",
      "c:\\anaconda3\\lib\\site-packages\\mne\\filter.py:333: UserWarning: Attenuation at stop frequency 14.5Hz is only 8.9dB.\n",
      "  '%0.1fdB.' % (att_freq, att_db))\n",
      "c:\\anaconda3\\lib\\site-packages\\mne\\filter.py:333: UserWarning: Attenuation at stop frequency 13.5Hz is only 9.0dB.\n",
      "  '%0.1fdB.' % (att_freq, att_db))\n",
      "c:\\anaconda3\\lib\\site-packages\\mne\\filter.py:333: UserWarning: Attenuation at stop frequency 39.5Hz is only 11.7dB.\n",
      "  '%0.1fdB.' % (att_freq, att_db))\n",
      "c:\\anaconda3\\lib\\site-packages\\mne\\filter.py:333: UserWarning: Attenuation at stop frequency 3.5Hz is only 19.7dB.\n",
      "  '%0.1fdB.' % (att_freq, att_db))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of labels 1027\n",
      "skip this instance\n",
      "skip this instance\n",
      "Extracting edf Parameters from suj9_d2final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 2589999  =      0.000 ...  2589.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 1 artifact by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    6, 3, 3, 6\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 2 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "Low-pass filtering at 5e+02 Hz\n",
      "Low-pass filtering at 1e+02 Hz\n",
      "length of labels 1114\n",
      "not putting in\n",
      "not putting in\n",
      "not putting in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\mne\\filter.py:333: UserWarning: Attenuation at stop frequency 14.5Hz is only 19.7dB.\n",
      "  '%0.1fdB.' % (att_freq, att_db))\n",
      "c:\\anaconda3\\lib\\site-packages\\mne\\filter.py:333: UserWarning: Attenuation at stop frequency 40.5Hz is only 19.7dB.\n",
      "  '%0.1fdB.' % (att_freq, att_db))\n"
     ]
    }
   ],
   "source": [
    "# initialization and preallocation\n",
    "TrainingLabel=[]\n",
    "TrainingData = []\n",
    "totoal_lenght = 0\n",
    "Fs=1000\n",
    "    \n",
    "# storing necessary features: raw data, low pass   \n",
    "for idx,item in enumerate(EDFfiles):\n",
    "    if item == 'suj13_l2nap_day2 edited.edf' or item =='suj13_l2nap_day2 edited1.edf':\n",
    "        pass\n",
    "    else:\n",
    "        file_to_read,fileName=eegPinelineDesign.pick_sample_file(EDFfiles,n=idx)\n",
    "        # channel list for artifact(eyemovement or chewing) removal - ROC and/or LOC\n",
    "        channelList = ['F3','F4','C3','C4','O1','O2','ROC','LOC']\n",
    "        raw = eegPinelineDesign.load_data(file_to_read,channelList,None, 100)# low pass\n",
    "        annotation_to_read = [x for x in Annotationfiles if fileName in x]\n",
    "        file = pd.read_csv(annotation_to_read[0])\n",
    "        windowsLabel = eegPinelineDesign.annotation_to_labels(Annotationfiles,fileName)\n",
    "        # parameterize annotations; use single number because the training output has one node only\n",
    "        # put a temporal label storage for counting\n",
    "        # channel list for extracting segments\n",
    "        # since the label is only one per training data segment, I add up the segments across all six channels\n",
    "        tempTrainingLabel=[]\n",
    "        channelList = ['F3','F4','C3','C4','O1','O2']\n",
    "        raw.pick_channels(channelList)\n",
    "        totoal_lenght += len(windowsLabel)\n",
    "        print('length of labels',totoal_lenght)\n",
    "        for sample,items in enumerate(windowsLabel):\n",
    "            if items not in ['w','1','2','3']:\n",
    "                print('not putting in')\n",
    "            else:\n",
    "                try:\n",
    "                    if items == 'w':\n",
    "                        TrainingLabel.append(0)\n",
    "                \n",
    "                    elif items == '1':\n",
    "                        TrainingLabel.append(1)\n",
    "                \n",
    "                    elif items == '2':\n",
    "                        TrainingLabel.append(2)\n",
    "                \n",
    "                    elif items == '3':\n",
    "                        TrainingLabel.append(3)\n",
    "                    #print('done labeling')\n",
    "                    for index,chan_names in enumerate(['F3','F4','C3','C4','O1','O2']):\n",
    "                        if index == 0:\n",
    "                            startPoint = sample*30;endPoint = (sample+1)*30\n",
    "                            start,stop = raw.time_as_index([startPoint,endPoint])\n",
    "                            tempSegment,time = raw[index,start:stop]\n",
    "                            tempdata = tempSegment\n",
    "                        else:\n",
    "                            startPoint = sample* 30;endPoint = (sample+1)*30\n",
    "                            start,stop = raw.time_as_index([startPoint,endPoint])\n",
    "                            tempSegment, time = raw[index,start:stop]\n",
    "                            tempdata += tempSegment\n",
    "                    #print('done segments')\n",
    "                    band_data = []\n",
    "                    delta_band = mne.filter.low_pass_filter(tempdata,Fs,4)\n",
    "                    theta_band = mne.filter.band_pass_filter(tempdata,Fs,4,7.5)\n",
    "                    alpha_band = mne.filter.band_pass_filter(tempdata,Fs,7.5,14)\n",
    "                    beta_band  = mne.filter.band_pass_filter(tempdata,Fs,14,40)\n",
    "                    gamma_band = mne.filter.high_pass_filter(tempdata,Fs,40)\n",
    "                    #print('done band pass')\n",
    "                    band_data.append([delta_band,theta_band,alpha_band,beta_band,gamma_band])\n",
    "    \n",
    "                    before_data_to_store=[]\n",
    "                    for freq_band in band_data[0]:\n",
    "                        coef,sigma = alg.AR_est_LD(np.array(freq_band)[0,:],2)\n",
    "                        before_data_to_store.append(np.append(coef,sigma))\n",
    "                    TrainingData.append(list(np.array(before_data_to_store).ravel()))\n",
    "                    #print(len(TrainingLabel),len(TrainingData))\n",
    "                \n",
    "                except:\n",
    "                    print('skip this instance')\n",
    "                    if len(TrainingLabel) != len(TrainingData):\n",
    "                        if len(TrainingLabel) > len(TrainingData):\n",
    "                            TrainingLabel.pop()\n",
    "                        elif len(TrainingLabel) > len(TrainingData):\n",
    "                            TrainingData.pop()\n",
    "                \n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Solver newton-cg supports only l2 penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2ffaf9bc1e67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrainingData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrainingLabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mclassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    163\u001b[0m         \"\"\"\n\u001b[0;32m    164\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    285\u001b[0m                 \u001b[1;34m\"not %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m                 self.label_binarizer_.classes_[i]])\n\u001b[1;32m--> 287\u001b[1;33m             for i, column in enumerate(columns))\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 804\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    660\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(estimator, X, y, classes)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         _check_solver_option(self.solver, self.multi_class, self.penalty,\n\u001b[1;32m-> 1148\u001b[1;33m                              self.dual, sample_weight)\n\u001b[0m\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36m_check_solver_option\u001b[1;34m(solver, multi_class, penalty, dual, sample_weight)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'l2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             raise ValueError(\"Solver %s supports only l2 penalties, \"\n\u001b[1;32m--> 417\u001b[1;33m                              \"got %s penalty.\" % (solver, penalty))\n\u001b[0m\u001b[0;32m    418\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdual\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m             raise ValueError(\"Solver %s supports only \"\n",
      "\u001b[1;31mValueError\u001b[0m: Solver newton-cg supports only l2 penalties, got l1 penalty."
     ]
    }
   ],
   "source": [
    "#clf = OneVsRestClassifier(SVC(kernel='linear',tol=1e-6,max_iter=5e5))\n",
    "clf = OneVsRestClassifier(LogisticRegression(penalty='l1',C=5,tol=10e-9,fit_intercept=True,solver='newton-cg',\n",
    "                                             max_iter=5e8,multi_class='ovr',n_jobs=-1))\n",
    "classification = make_pipeline(StandardScaler(),clf)\n",
    "\n",
    "#classification=[]\n",
    "\n",
    "X = np.array(TrainingData)\n",
    "Y = np.array(TrainingLabel)\n",
    "classification.fit(X,Y)\n",
    "print(classification_report(classification.predict(X),Y))\n",
    "print(classification.score(X,Y))\n",
    "print('predict:',classification.predict(X)[0:200])\n",
    "print('actual: ',Y[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(LogisticRegression(penalty='l1',C=5,tol=10e-9,fit_intercept=True,solver='liblinear',\n",
    "                                             max_iter=5e8,multi_class='ovr',n_jobs=-1))\n",
    "classification = make_pipeline(StandardScaler(),clf)\n",
    "n_samples=X.shape[0]\n",
    "cv = ShuffleSplit(n_samples, n_iter=3,test_size=0.3, random_state=0)\n",
    "scores = cross_val_score(classification, X, Y,cv=cv, scoring='accuracy')\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_scale = scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# transfer funtion\n",
    "#\n",
    "def sgm(x,Derivative = False):\n",
    "    if not Derivative:\n",
    "        return 1.0 / (1.0+np.exp(-x))\n",
    "    else:\n",
    "        out = sgm(x)\n",
    "        return out*(1.0-out)\n",
    "    \n",
    "def linear(x,Derivative = False):\n",
    "    if not Derivative:\n",
    "        return x\n",
    "    else:\n",
    "        return 1.0\n",
    "    \n",
    "def gaussian(x, Derivative = False):\n",
    "    if not Derivative:\n",
    "        return np.exp(-x**2)\n",
    "    else:\n",
    "        return -2*x*np.exp(-x**2)\n",
    "    \n",
    "def tanh(x, Derivative = False):\n",
    "    if not Derivative:\n",
    "        return np.tanh(x)\n",
    "    else:\n",
    "        return 1 - np.tanh(x)**2\n",
    "            \n",
    "\n",
    "#\n",
    "#Class\n",
    "#\n",
    "\n",
    "\n",
    "class BackPropagationNetwork:\n",
    "    \"\"\"A back-propagation Network\"\"\"\n",
    "    \n",
    "    #\n",
    "    # Class members\n",
    "    #\n",
    "    layerCount = 0\n",
    "    shape = None\n",
    "    weights=[]\n",
    "    # Family of functions\n",
    "    tFuncs = []\n",
    "    #\n",
    "    # Class methods\n",
    "    #\n",
    "    def __init__(self, layerSize,layerFunctions = None):\n",
    "        \"\"\" Initialize the network\"\"\"\n",
    "        \n",
    "        # layer info\n",
    "        self.layerCount = len(layerSize) -1\n",
    "        self.shape = layerSize\n",
    "        \n",
    "        if layerFunctions is None:\n",
    "            lFuncs = []\n",
    "            for i in range(self.layerCount):\n",
    "                if i == self.layerCount - 1:\n",
    "                    lFuncs.append(linear)\n",
    "                else:\n",
    "                    lFuncs.append(sgm)\n",
    "        else:\n",
    "            if len(layerSize) != len(layerFunctions):\n",
    "                raise ValueError(\"Incompatible list of transfer functions.\")\n",
    "            elif layerFunctions[0] is not None:\n",
    "                raise ValueError(\"Input layer cannot have a transfer function.\")\n",
    "            else:\n",
    "                lFuncs = layerFunctions[1:]\n",
    "                \n",
    "                    \n",
    "        self.tFuncs = lFuncs\n",
    "        \n",
    "        # Data from last Run\n",
    "        self._layerInput = []\n",
    "        self._layerOutput = []\n",
    "        self._previousWeightDelta = []\n",
    "        \n",
    "        # Create the weight arrays\n",
    "        for (l1,l2) in zip(layerSize[:-1],layerSize[1:]):\n",
    "            self.weights.append(np.random.uniform(low=-0.5,high=0.5,size=(l2,l1+1)))\n",
    "            self._previousWeightDelta.append(np.zeros((l2,l1+1)))\n",
    "\n",
    "            \n",
    "    #\n",
    "    # Run method\n",
    "    #\n",
    "    def Run(self,input):\n",
    "        \"\"\"Run the network based on the input data\"\"\"\n",
    "        \n",
    "        lnCases = input.shape[0]\n",
    "        \n",
    "        # Clear out the previous intermediate value lists\n",
    "        self._layerInput=[]\n",
    "        self._layerOutput=[]\n",
    "        \n",
    "        # Run it!\n",
    "        for index in range(self.layerCount):\n",
    "            # Determine layer input\n",
    "            if index ==0:\n",
    "                layerInput = self.weights[0].dot(np.vstack([input.T,np.ones([1,lnCases])]))\n",
    "            else:\n",
    "                layerInput = self.weights[index].dot(np.vstack([self._layerOutput[-1],np.ones([1,lnCases])]))\n",
    "                \n",
    "            self._layerInput.append(layerInput)\n",
    "            self._layerOutput.append(self.tFuncs[index](layerInput))\n",
    "        return self._layerOutput[-1].T\n",
    "    \n",
    "    #\n",
    "    # TrainEpoch method\n",
    "    #\n",
    "    def TrainEpoch(self, input,target, trainingRate = 0.2,momentum = 0.5):\n",
    "        \"\"\"This method trains the network for one epoch\"\"\"\n",
    "        \n",
    "        delta = []\n",
    "        lnCases = input.shape[0]\n",
    "        \n",
    "        # First run the network\n",
    "        self.Run(input)\n",
    "        \n",
    "        # Calculate our deltas\n",
    "        for index in reversed(range(self.layerCount)):\n",
    "            if index == self.layerCount -1:\n",
    "                # compare to the target values\n",
    "                output_delta = self._layerOutput[index] - target.T\n",
    "                error = np.sum(output_delta**2)\n",
    "                delta.append(output_delta * self.tFuncs[index](self._layerInput[index],True))\n",
    "            else:\n",
    "                #Compare to the following layer's delta\n",
    "                delta_pullback = self.weights[index + 1].T.dot(delta[-1])\n",
    "                delta.append(delta_pullback[:-1,:] * self.tFuncs[index](self._layerInput[index],True))\n",
    "                \n",
    "            \n",
    "        # Compute weight deltas\n",
    "        for index in range(self.layerCount):\n",
    "            delta_index = self.layerCount - 1 - index\n",
    "            \n",
    "            if index == 0:\n",
    "                layerOutput = np.vstack([input.T, np.ones([1,lnCases])])\n",
    "            else:\n",
    "                layerOutput = np.vstack([self._layerOutput[index -1],np.ones([1,self._layerOutput[index-1].shape[1]])])\n",
    "                \n",
    "            curWeightDelta = np.sum(\\\n",
    "                                layerOutput[None,:,:].transpose(2,0,1) * delta[delta_index][None,:,:].transpose(2,1,0)\\\n",
    "                                ,axis = 0)\n",
    "            weightDelta = trainingRate * curWeightDelta + momentum * self._previousWeightDelta[index]\n",
    "            \n",
    "            self.weights[index] -= weightDelta\n",
    "            \n",
    "            self._previousWeightDelta[index] = weightDelta\n",
    "            \n",
    "            \n",
    "        return error\n",
    "    \n",
    "    # Transfer functions is moved outside the class\n",
    "    \n",
    "#\n",
    "# if run as a script, create a test object\n",
    "#\n",
    "if __name__ == \"__main__\":\n",
    "    #bpn = BackPropagationNetwork((2,2,1))\n",
    "    #print(bpn.shape)\n",
    "    #print(bpn.weights)\n",
    "    \n",
    "    lvInput = X_scale\n",
    "    lvTarget = Y\n",
    "    lFuncs = [None,sgm,sgm, gaussian]\n",
    "    bpn = BackPropagationNetwork((X_scale.shape[1],8,2,1),lFuncs)\n",
    "    lnMax = 100000\n",
    "    lnErr = 1e-5\n",
    "    for i in range(lnMax+1):\n",
    "        err = bpn.TrainEpoch(lvInput, lvTarget,momentum=0.1)\n",
    "        if i % 2500 == 0:\n",
    "            print(\"Iteration {a}\\tError: {b:0.6f}\".format(a=i, b=err))\n",
    "        if err <= lnErr:\n",
    "            print(\"Desired error reached. Iter: {0}\".format(i))\n",
    "            break\n",
    "    # Display output\n",
    "    lvOutput = bpn.Run(lvInput)\n",
    "    for i in range(lvInput.shape[0][40:60]):\n",
    "        print(\"Input: {0}\\nOutput: {1}\".format(lvInput[i],lvOutput[i]))\n",
    "    #print(\"Input: {0}\\nOutput: {1}\".format(lvInput,lvOutput))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
