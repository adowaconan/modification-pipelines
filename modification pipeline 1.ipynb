{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py:7: DeprecationWarning: bad escape \\s\n",
      "  from pandas import hashtable, tslib, lib\n",
      "C:\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility\n",
      "  return f(*args, **kwds)\n",
      "C:\\Anaconda3\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import mne\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import scipy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA,FastICA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from scipy.fftpack import fft,ifft\n",
    "import math\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "from scipy.signal import spectrogram\n",
    "from mne.preprocessing.ica import ICA\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['64chlocs.elp', 'label_extraction.npy', 'label_extraction.pkl', 's5d2_final.edf', 's5d2_final_annotations.txt', 's6n2_final.edf', 's6n2_final_annotations.txt', 'Sleep Stage Scoring Criteria.docx', 'suj10_d1final.edf', 'suj10_d1final_annotations.txt', 'suj10_d2final.edf', 'suj10_d2final_annotations.txt', 'suj13_l2nap_day2 edited.edf', 'suj13_l2nap_day2 edited1.edf', 'suj13_l2nap_day2 edited1_annotations.txt', 'suj13_l2nap_day2 edited_annotations.txt', 'suj13_l2nap_day2 edited_C3.txt', 'suj13_l2nap_day2 edited_C4.txt', 'suj13_l2nap_day2 edited_F3.txt', 'suj13_l2nap_day2 edited_F4.txt', 'suj13_l2nap_day2 edited_O1.txt', 'suj13_l2nap_day2 edited_O2.txt', 'suj5_d1final.edf', 'suj5_d1final_annotations.txt', 'suj6_d1final.edf', 'suj6_d1final_annotations.txt', 'suj8_d1final.edf', 'suj8_d1final_annotations.txt', 'suj8_d2final.edf', 'suj8_d2final_annotations.txt', 'suj9_d1final.edf', 'suj9_d1final_annotations.txt', 'suj9_d2final.edf', 'suj9_d2final_annotations.txt', 'testing-montage-2.mtg', 'Training Data Frame']\n"
     ]
    }
   ],
   "source": [
    "os.chdir('C:/Users/ning/Downloads/training set')\n",
    "print(os.listdir(os.getcwd()))\n",
    "directoryList = os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EDFFind = re.compile(\"edf\", re.IGNORECASE);EDFfiles=[]\n",
    "TXTFind = re.compile(\"txt\",re.IGNORECASE);TXTfiles=[]\n",
    "for item in directoryList:\n",
    "    if EDFFind.search(item):\n",
    "        EDFfiles.append(item)\n",
    "    elif TXTFind.search(item):\n",
    "        TXTfiles.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pick_sample_file(EDFfiles,n=0):\n",
    "    file_to_read=EDFfiles[n]\n",
    "    fileName = file_to_read.split('.')[0]\n",
    "    return file_to_read,fileName\n",
    "def load_data(file_to_read,channelList,low_frequency=5,high_frequency=50):\n",
    "    \"\"\" not just the data, but also remove artifact by using mne.ICA\"\"\"\n",
    "    raw = mne.io.read_raw_edf(file_to_read,stim_channel=None,preload=True)\n",
    "    raw.pick_channels(channelList)\n",
    "    if low_frequency != None and high_frequency != None:\n",
    "        raw.filter(low_frequency,high_frequency)\n",
    "    elif low_frequency != None or high_frequency != None:\n",
    "        try: \n",
    "            raw.filter(low_frequency,500)\n",
    "        except:\n",
    "            raw.filter(0,high_frequency)\n",
    "    else:\n",
    "        raw = raw\n",
    "    ica = ICA(n_components=None, n_pca_components=None, max_pca_components=None,max_iter=1000,\n",
    "          noise_cov=None, random_state=0)\n",
    "    picks=mne.pick_types(raw.info,meg=False,eeg=True,eog=False,stim=False)\n",
    "    ica.fit(raw,picks=picks,decim=3,reject=dict(mag=4e-12, grad=4000e-13))\n",
    "    ica.detect_artifacts(raw,eog_ch='ROC',eog_criterion=0.5)\n",
    "    clean_raw = ica.apply(raw,exclude=ica.exclude)\n",
    "    \n",
    "    \n",
    "    return clean_raw\n",
    "\n",
    "def annotation_to_labels(TXTfiles,sample_number=0,label='markon',last_letter=-1):\n",
    "    annotation_to_read=[x for x in TXTfiles if fileName in x]\n",
    "    file = pd.read_csv(annotation_to_read[0])\n",
    "    #file['Duration'] = file['Duration'].fillna(0)\n",
    "    labelFind = re.compile(label,re.IGNORECASE)\n",
    "    windowLabel=[]\n",
    "    for row in file.iterrows():\n",
    "        currentEvent = row[1][-1]\n",
    "        if (labelFind.search(currentEvent)):\n",
    "          \n",
    "            windowLabel.append(currentEvent[-1])\n",
    "    for idx,items in enumerate(windowLabel):\n",
    "        if items == ' ':\n",
    "            windowLabel[idx] = windowLabel[idx -1]\n",
    "    return windowLabel\n",
    "def relabel_to_binary(windowLabel,label=['2','3']):\n",
    "    YLabel=[]\n",
    "    for row in windowLabel:\n",
    "        if row[0] == label[0] or row[0] == label[1]:\n",
    "            YLabel.append(1)\n",
    "        else:\n",
    "            YLabel.append(0)\n",
    "    return YLabel\n",
    "unit_step=lambda x:0 if x<0 else 1\n",
    "def structure_to_data(channelList,YLabel,raw,sample_points=1000):\n",
    "    data={}\n",
    "    for channel_names in channelList:\n",
    "        data[channel_names]=[]\n",
    "    data['label']=[]\n",
    "    channel_index = mne.pick_types(raw.info,meg=False,eeg=True,eog=False,stim=False)\n",
    "    for sample,labels in zip(range(len(YLabel)),YLabel):\n",
    "        \n",
    "        try:\n",
    "            startPoint=30*sample;endPoint=30*(sample+1)\n",
    "            start,stop=raw.time_as_index([startPoint,endPoint])\n",
    "            segment,time=raw[channel_index,start:stop]\n",
    "            \n",
    "            for idx, channel_names in enumerate(channelList):\n",
    "                yf = 20*np.log10(np.abs(np.fft.rfft(segment[idx,:sample_points])))\n",
    "                data[channel_names].append(yf)\n",
    "            data['label'].append(labels)\n",
    "        except:\n",
    "            print('last window is missing due to error','sample that is passed is',sample)\n",
    "            #data['label']=scipy.delete(YLabel,sample,0)\n",
    "            pass\n",
    "            \n",
    "    return data\n",
    "def merge_dicts(dict1,dict2):\n",
    "    for key, value in dict2.items():\n",
    "        dict1.setdefault(key,[]).extend(value)\n",
    "    return dict1\n",
    "\n",
    "def logistic_func(theta, x):\n",
    "    return 1./(1+np.exp(x.dot(theta)))\n",
    "def log_gradient(theta, x, y):\n",
    "    first_calc = logistic_func(theta, x) - np.squeeze(y)\n",
    "    final_calc = first_calc.T.dot(x)\n",
    "    return final_calc\n",
    "def cost_func(theta, x, y):\n",
    "    log_func_v = logistic_func(theta,x)\n",
    "    y = np.squeeze(y)\n",
    "    step1 = y * np.log(log_func_v)\n",
    "    step2 = (1-y) * np.log(1 - log_func_v)\n",
    "    final = -step1 - step2\n",
    "    return np.mean(final)\n",
    "def grad_desc(theta_values, X, y, lr=10e-8, converge_change=10e-6):\n",
    "    #normalize\n",
    "    #X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "    #setup cost iter\n",
    "    cost_iter = []\n",
    "    cost = cost_func(theta_values, X, y)\n",
    "    cost_iter.append([0, cost])\n",
    "    change_cost = 1\n",
    "    i = 1\n",
    "    while(change_cost > converge_change):\n",
    "        old_cost = cost\n",
    "        theta_values = theta_values - (lr * log_gradient(theta_values, X, y))\n",
    "        cost = cost_func(theta_values, X, y)\n",
    "        cost_iter.append([i, cost])\n",
    "        change_cost = old_cost - cost\n",
    "        i+=1;#print(i)\n",
    "    return theta_values, np.array(cost_iter)\n",
    "def pred_values(theta, X, hard=True,one_sample=False):\n",
    "    #normalize\n",
    "    if not one_sample:\n",
    "        X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "    pred_prob = logistic_func(theta, X)\n",
    "    pred_value = np.where(pred_prob >= .5, 1, 0)\n",
    "    if hard:\n",
    "        return pred_value\n",
    "    return pred_prob\n",
    "def SK_to_data(channelList,markPairs,dataLabels,raw):\n",
    "    data={}\n",
    "    for channel_names in channelList:\n",
    "        data[channel_names]=[]\n",
    "    data['label']=[]\n",
    "    channel_index,_=dictionary_for_target_channels(channelList,raw)\n",
    "    for sample,pairs in enumerate(markPairs):\n",
    "        #print(idx)\n",
    "        \n",
    "        start,stop = raw.time_as_index(pairs)\n",
    "            \n",
    "        segment,time=raw[channel_index,start:stop]\n",
    "        try:    \n",
    "            for idx,channel_names in enumerate(channelList):\n",
    "                yf = fft(segment[idx,:]);N=100;#print(channel_names,N)\n",
    "                data[channel_names].append(np.abs(yf[0:100]))\n",
    "            data['label'].append(dataLabels[sample])\n",
    "        except:\n",
    "            continue\n",
    "       \n",
    "    return data\n",
    "def annotation_file(TXTFiles,sample_number=0):\n",
    "    annotation_to_read=[x for x in TXTfiles if fileName in x]\n",
    "    file = pd.read_csv(annotation_to_read[0])\n",
    "    #file['Duration'] = file['Duration'].fillna(0)\n",
    "    return file\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def center_window_by_max_amplitude(raw,time,channelList,windowsWidth=2.0):\n",
    "    startPoint=time-windowsWidth;endPoint=time+windowsWidth\n",
    "    start,stop=raw.time_as_index([startPoint,endPoint])\n",
    "    tempsegment,timespan=raw[:,start:stop]\n",
    "    centerxval = timespan[np.argmax(abs(tempsegment[ii,:]))]\n",
    "    startPoint=centerxval-windowsWidth/2;endPoint=centerxval+windowsWidth/2\n",
    "    start,stop=raw.time_as_index([startPoint,endPoint])\n",
    "    segment,_=raw[:,start:stop]\n",
    "    segment_dictionary={}\n",
    "    for idx,name in enumerate(channelList):\n",
    "        yf = fft(segment[idx,:])[:50] \n",
    "        segment_dictionary[name]= abs(yf)\n",
    "    return segment_dictionary\n",
    "\n",
    "def from_time_markers_to_sample(channelList,raw,windowsWidth=2.0):\n",
    "    data={}\n",
    "    for names in channelList:\n",
    "        data[names]=[]\n",
    "    for moments in time:\n",
    "        segments=center_window_by_max_amplitude(raw,moments, channelList,windowsWidth=windowsWidth)\n",
    "        for names in channelList:\n",
    "            data[names.append(segments[names])]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put all the data together - 30s\n",
      "s5d2_final.edf\n",
      "Extracting edf Parameters from s5d2_final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3383999  =      0.000 ...  3383.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Band-pass filtering from 5 - 50 Hz\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    1, 7, 0, 6, 3\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 5 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "113 113\n",
      "F3\n",
      "train_data (0, 101) temp_data (113, 101)\n",
      "F4\n",
      "train_data (0, 101) temp_data (113, 101)\n",
      "C3\n",
      "train_data (0, 101) temp_data (113, 101)\n",
      "C4\n",
      "train_data (0, 101) temp_data (113, 101)\n",
      "O1\n",
      "train_data (0, 101) temp_data (113, 101)\n",
      "O2\n",
      "train_data (0, 101) temp_data (113, 101)\n",
      "s6n2_final.edf\n",
      "Extracting edf Parameters from s6n2_final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 2073999  =      0.000 ...  2073.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Band-pass filtering from 5 - 50 Hz\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 1 artifact by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    3, 1, 2, 3\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "70 70\n",
      "F3\n",
      "train_data (113, 101) temp_data (70, 101)\n",
      "F4\n",
      "train_data (113, 101) temp_data (70, 101)\n",
      "C3\n",
      "train_data (113, 101) temp_data (70, 101)\n",
      "C4\n",
      "train_data (113, 101) temp_data (70, 101)\n",
      "O1\n",
      "train_data (113, 101) temp_data (70, 101)\n",
      "O2\n",
      "train_data (113, 101) temp_data (70, 101)\n",
      "suj10_d1final.edf\n",
      "Extracting edf Parameters from suj10_d1final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3601999  =      0.000 ...  3601.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Band-pass filtering from 5 - 50 Hz\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 4 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    2, 5, 6, 7, 2, 2, 1\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 5 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "121 121\n",
      "F3\n",
      "train_data (183, 101) temp_data (121, 101)\n",
      "F4\n",
      "train_data (183, 101) temp_data (121, 101)\n",
      "C3\n",
      "train_data (183, 101) temp_data (121, 101)\n",
      "C4\n",
      "train_data (183, 101) temp_data (121, 101)\n",
      "O1\n",
      "train_data (183, 101) temp_data (121, 101)\n",
      "O2\n",
      "train_data (183, 101) temp_data (121, 101)\n",
      "suj10_d2final.edf\n",
      "Extracting edf Parameters from suj10_d2final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3704999  =      0.000 ...  3704.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Band-pass filtering from 5 - 50 Hz\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    1, 4, 1, 4, 2\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "last window is missing due to error sample that is passed is 124\n",
      "124 124\n",
      "F3\n",
      "train_data (304, 101) temp_data (124, 101)\n",
      "F4\n",
      "train_data (304, 101) temp_data (124, 101)\n",
      "C3\n",
      "train_data (304, 101) temp_data (124, 101)\n",
      "C4\n",
      "train_data (304, 101) temp_data (124, 101)\n",
      "O1\n",
      "train_data (304, 101) temp_data (124, 101)\n",
      "O2\n",
      "train_data (304, 101) temp_data (124, 101)\n",
      "suj13_l2nap_day2 edited.edf\n",
      "Extracting edf Parameters from suj13_l2nap_day2 edited.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 1805999  =      0.000 ...  1805.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Band-pass filtering from 5 - 50 Hz\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 6 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    0, 1, 4, 5, 6, 7, 3, 4, 2\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 8 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n",
      "22 22\n",
      "F3\n",
      "train_data (428, 101) temp_data (22, 101)\n",
      "F4\n",
      "train_data (428, 101) temp_data (22, 101)\n",
      "C3\n",
      "train_data (428, 101) temp_data (22, 101)\n",
      "C4\n",
      "train_data (428, 101) temp_data (22, 101)\n",
      "O1\n",
      "train_data (428, 101) temp_data (22, 101)\n",
      "O2\n",
      "train_data (428, 101) temp_data (22, 101)\n",
      "suj13_l2nap_day2 edited1.edf\n",
      "Extracting edf Parameters from suj13_l2nap_day2 edited1.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 1805399  =      0.000 ...  1805.399 secs...\n",
      "[done]\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\fastica_.py:116: UserWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn('FastICA did not converge. Consider increasing '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No channels match the selection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d0c0d3d1df48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mfile_to_read\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfileName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpick_sample_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEDFfiles\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_to_read\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mraw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_to_read\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchannelList\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mchannelList\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'F3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'F4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'O1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'O2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mwindowLabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mannotation_to_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTXTfiles\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msample_number\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_number\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'markon'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-0945936482a1>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(file_to_read, channelList, low_frequency, high_frequency)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;34m\"\"\" not just the data, but also remove artifact by using mne.ICA\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_raw_edf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_to_read\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstim_channel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpick_channels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannelList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlow_frequency\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhigh_frequency\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlow_frequency\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhigh_frequency\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\mne\\channels\\channels.py\u001b[0m in \u001b[0;36mpick_channels\u001b[1;34m(self, ch_names, copy)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mch_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mch_names\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mch_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[0minst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pick_drop_channels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minst\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\mne\\channels\\channels.py\u001b[0m in \u001b[0;36m_pick_drop_channels\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    476\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpick_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minst_has\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_projector'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\mne\\io\\pick.py\u001b[0m in \u001b[0;36mpick_info\u001b[1;34m(info, sel, copy)\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No channels match the selection.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'chs'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'chs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No channels match the selection."
     ]
    }
   ],
   "source": [
    "print('put all the data together - 30s')\n",
    "data={};channelList=['F3','F4','C3','C4','O1','O2']\n",
    "for name in channelList:\n",
    "    data[name]=np.empty([0,101])\n",
    "data['label']=np.empty([0,2])\n",
    "for sample_number in range(len(EDFfiles)):\n",
    "    channelList=['F3','F4','C3','C4','O1','O2','ROC','LOC']\n",
    "    file_to_read,fileName = pick_sample_file(EDFfiles,n=sample_number)\n",
    "    print(file_to_read)\n",
    "    raw=load_data(file_to_read,channelList,5,50)\n",
    "    channelList=['F3','F4','C3','C4','O1','O2']\n",
    "    windowLabel=annotation_to_labels(TXTfiles,sample_number=sample_number,label='markon')\n",
    "    raw.pick_channels(channelList)\n",
    "    YLabel = label_binarize(windowLabel,classes=['2','3'])\n",
    "    temp_data=structure_to_data(channelList,YLabel,raw,sample_points=200)\n",
    "    print(len(temp_data['F3']),len(temp_data['label']))\n",
    "    for names in channelList:\n",
    "        print(names)\n",
    "        print('train_data',np.array(data[names]).shape,'temp_data',np.array(temp_data[names]).shape)\n",
    "        data[names]=np.concatenate((data[names],temp_data[names]),axis=0)\n",
    "    data['label']=np.concatenate((data['label'],temp_data['label']),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name='C3'\n",
    "X=data[name]\n",
    "Y=data['label']\n",
    "for ii in range(len(Y)):\n",
    "    plt.plot(X[ii],'b',alpha=0.02)\n",
    "    if Y[ii,1] == 1:\n",
    "        plt.plot(X[ii],'r',label=Y[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for names in channelList:\n",
    "    plt.figure(names)\n",
    "    X = data[names]\n",
    "    Y = data['label']\n",
    "    \n",
    "    n_class=Y.shape[1]\n",
    "    \n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.5,random_state=101)\n",
    "    \n",
    "    clf=clf = OneVsRestClassifier(SVC(kernel='linear',probability=True,random_state=101))\n",
    "    \n",
    "    y_score=clf.fit(x_train,y_train).decision_function(x_test)\n",
    "    print(y_score.shape,y_test.shape)\n",
    "    precision={};recall={};average_precision={}\n",
    "    \n",
    "    \n",
    "    for i in range(n_class):\n",
    "        precision[i],recall[i],_=precision_recall_curve(y_test[:,i],y_score[i,:])\n",
    "        average_precision[i]=average_precision_score(y_test[:,i].ravel(),y_score[i,:].ravel())\n",
    "    average_precision['micro']=average_precision_score(y_test,y_score,average='micro')\n",
    "    \n",
    "    \n",
    "    plt.clf()\n",
    "    plt.plot(recall[0],precision[0],label='precision-recall curve')\n",
    "    plt.xlabel('recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision[0]))\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # Plot Precision-Recall curve for each class\n",
    "    plt.clf()\n",
    "    plt.plot(recall[\"micro\"], precision[\"micro\"],\n",
    "             label='micro-average Precision-recall curve (area = {0:0.2f})'.format(average_precision[\"micro\"]))\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(recall[i], precision[i],\n",
    "                 label='Precision-recall curve of class {0} (area = {1:0.2f})'.format(i, average_precision[i]))\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Extension of Precision-Recall curve to multi-class')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suj10_d2final.edf\n",
      "Extracting edf Parameters from suj10_d2final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3704999  =      0.000 ...  3704.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Band-pass filtering from 5 - 50 Hz\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    1, 4, 1, 4, 2\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n"
     ]
    }
   ],
   "source": [
    "channelList=['F3','F4','C3','C4','O1','O2','ROC','LOC']\n",
    "file_to_read,fileName = pick_sample_file(EDFfiles,n=3)\n",
    "print(file_to_read)\n",
    "\n",
    "raw=load_data(file_to_read,channelList,5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "windowLabel=annotation_to_labels(TXTfiles,sample_number=3,label='markon')\n",
    "\n",
    "channelList=['F3','F4','C3','C4','O1','O2']\n",
    "raw.pick_channels(channelList)\n",
    "\n",
    "YLabel = label_binarize(windowLabel,classes=['2','3'])\n",
    "train_data=structure_to_data(channelList,YLabel,raw,sample_points=1000)\n",
    "YLabel.sum(axis=0)/len(YLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channelList=['F3','F4','C3','C4','O1','O2','ROC','LOC']\n",
    "file_to_read,fileName = pick_sample_file(EDFfiles,n=1)\n",
    "print(file_to_read)\n",
    "\n",
    "raw=load_data(file_to_read,channelList,5,50)\n",
    "\n",
    "windowLabel=annotation_to_labels(TXTfiles,sample_number=1,label='markon')\n",
    "\n",
    "channelList=['F3','F4','C3','C4','O1','O2']\n",
    "raw.pick_channels(channelList)\n",
    "\n",
    "YLabel = label_binarize(windowLabel,classes=['2','3'])\n",
    "validation_data=structure_to_data(channelList,YLabel,raw,sample_points=1000)\n",
    "YLabel.sum(axis=0)/len(YLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suj10_d1final.edf\n",
      "Extracting edf Parameters from suj10_d1final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3601999  =      0.000 ...  3601.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Band-pass filtering from 8 - 22 Hz\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    6, 7, 7, 6, 3\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n"
     ]
    }
   ],
   "source": [
    "channelList=['F3','F4','C3','C4','O1','O2','ROC','LOC']\n",
    "file_to_read,fileName = pick_sample_file(EDFfiles,n=2)\n",
    "print(file_to_read)\n",
    "#http://www.eurasip.org/Proceedings/Eusipco/Eusipco2005/defevent/papers/cr1847.pdf\n",
    "raw=load_data(file_to_read,channelList,8,22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 25)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFXQRkUyooIuIZOL/AeKorGqrPd/sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2210030acf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "signal = raw._data[0,60000:120000]\n",
    "signal.shape\n",
    "f,t,Sxx = spectrogram(signal,fs=1000,window=('hamming'),nperseg=512,noverlap=511)\n",
    "plt.pcolormesh(t,f,Sxx)\n",
    "plt.ylim([0,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample=1\n",
    "startPoint=30*sample;endPoint=30*(sample+1)\n",
    "start,stop=raw.time_as_index([startPoint,endPoint])\n",
    "segment,time=raw[:,start:stop]\n",
    "for idx, channel_names in enumerate(channelList):\n",
    "    yf = mne.time_frequency.stft(segment[idx,:],32,8)\n",
    "    xf = np.linspace(0, 1000/2, len(yf))\n",
    "    #plt.figure(idx)\n",
    "    #plt.plot(yf)\n",
    "#STFT_raw =mne.time_frequency.stft(raw,32,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def center_window_by_max_amplitude(raw,time,channelList,windowsWidth=2.0):\n",
    "    startPoint=time-windowsWidth;endPoint=time+windowsWidth\n",
    "    start,stop=raw.time_as_index([startPoint,endPoint])\n",
    "    tempsegment,timespan=raw[:,start:stop]\n",
    "    segment_dictionary={}\n",
    "    for idx,name in enumerate(channelList):\n",
    "        centerxval = timespan[np.argmax(abs(tempsegment[idx,:]))]\n",
    "        startPoint=centerxval-windowsWidth/2;endPoint=centerxval+windowsWidth/2\n",
    "        start,stop=raw.time_as_index([startPoint,endPoint])\n",
    "        segment,_=raw[idx,start:stop]\n",
    "    \n",
    "        normalized_segment = (segment-np.mean(segment))/scipy.linalg.norm(segment)\n",
    "        #yf = fft(segment[idx,:])[:50] \n",
    "        segment_dictionary[name]= normalized_segment\n",
    "    return segment_dictionary\n",
    "\n",
    "def from_time_markers_to_sample(channelList,raw,windowsWidth=2.0):\n",
    "    data={}\n",
    "    for names in channelList:\n",
    "        data[names]=[]\n",
    "    for moments in time:\n",
    "        segments=center_window_by_max_amplitude(raw,moments, channelList,windowsWidth=windowsWidth)\n",
    "        for names in channelList:\n",
    "            data[names].append(segments[names])\n",
    "    return data\n",
    "\n",
    "def generate_label_sample(file,channelList,raw,windowsWidth=2.0,label='spindle'):\n",
    "    data={};targetFind = re.compile(label, re.IGNORECASE);moments=0\n",
    "    for names in channelList:\n",
    "        data[names]=[]\n",
    "    for row in file.iterrows():\n",
    "        currentEvent=row[1][-1]\n",
    "        if targetFind.search(currentEvent):\n",
    "            moments=row[1][0]\n",
    "        segments=center_window_by_max_amplitude(raw,moments, channelList,windowsWidth=windowsWidth)\n",
    "        for names in channelList:\n",
    "            data[names].append(segments[names])\n",
    "    return data\n",
    "\n",
    "def generate_nonevent_sample(raw,file,channelList,windowsWidth=2.0,exclude=['spindle','k-complex']):\n",
    "    time_range=raw.last_samp/1000;initial_condition=file.iloc[0,-1];cnt=0\n",
    "    while initial_condition != 'spindle':\n",
    "        cnt +=1\n",
    "        initial_condition = file.iloc[cnt,-1]\n",
    "        \n",
    "    \n",
    "    initial_moment = file.iloc[cnt,-1]\n",
    "    while initial_moment in exclude:\n",
    "        time_stamp = random.randrange(0,time_range)\n",
    "        startPoint=time_stamp-windowsWidth;endPoint=time_stamp+windowsWidth\n",
    "        for row in file.iterrows():\n",
    "            if startPoint<=row[1][0]<=endPoint:\n",
    "                initial_moment=str(row[1][-1]).lower()\n",
    "            else:\n",
    "                initial_moment='non-event'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-1768d0c4bee5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mannotation_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTXTfiles\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msample_number\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mspindles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerate_label_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchannelList\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-156880958d2d>\u001b[0m in \u001b[0;36mgenerate_label_sample\u001b[1;34m(file, channelList, raw, windowsWidth, label)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtargetFind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrentEvent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mmoments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0msegments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcenter_window_by_max_amplitude\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmoments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannelList\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindowsWidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwindowsWidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchannelList\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-156880958d2d>\u001b[0m in \u001b[0;36mcenter_window_by_max_amplitude\u001b[1;34m(raw, time, channelList, windowsWidth)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msegment_dictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannelList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mcenterxval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimespan\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtempsegment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mstartPoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcenterxval\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mwindowsWidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m;\u001b[0m\u001b[0mendPoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcenterxval\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mwindowsWidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_as_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstartPoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mendPoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "file=annotation_file(TXTfiles,sample_number=2)\n",
    "spindles=generate_label_sample(file,channelList,raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data={}\n",
    "for channel_names in channelList:\n",
    "    train_data[channel_names]=[]\n",
    "train_data['label']=[]\n",
    "channel_index=mne.pick_types(raw.info,meg=False,eeg=True,eog=False,stim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(YLabel)/len(YLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sample in range(len(YLabel)):\n",
    "    startPoint=30*sample;endPoint=30*(sample+1)\n",
    "    start,stop=raw.time_as_index([startPoint,endPoint])\n",
    "    segment,time=raw[channel_index,start:stop]\n",
    "    for idx, channel_names in enumerate(channelList):\n",
    "        yf = 20*np.log10(np.abs(np.fft.rfft(segment[idx,:1000])))\n",
    "        train_data[channel_names].append(yf)\n",
    "    train_data['label'].append(YLabel[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample=1\n",
    "startPoint=30*sample;endPoint=30*(sample+1)\n",
    "start,stop=raw.time_as_index([startPoint,endPoint])\n",
    "segment,time=raw[channel_index,start:stop]\n",
    "for idx, channel_names in enumerate(channelList):\n",
    "    yf = 20*np.log10(np.abs(np.fft.rfft(segment[idx,:])))\n",
    "    xf = np.linspace(0, 1000/2, len(yf))\n",
    "    plt.figure(idx)\n",
    "    plt.plot(yf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channelList=['F3','F4','C3','C4','O1','O2','ROC','LOC']\n",
    "file_to_read,fileName = pick_sample_file(EDFfiles,n=1)\n",
    "print(file_to_read)\n",
    "\n",
    "raw=load_data(file_to_read,channelList,5,50)\n",
    "windowLabel=annotation_to_labels(TXTfiles,sample_number=0,label='markon')\n",
    "channelList=['F3','F4','C3','C4','O1','O2']\n",
    "raw.pick_channels(channelList)\n",
    "YLabel = label_binarize(['2','3'],classes=['w','1','2','3'])\n",
    "validation_data={}\n",
    "for channel_names in channelList:\n",
    "    validation_data[channel_names]=[]\n",
    "validation_data['label']=[]\n",
    "channel_index=mne.pick_types(raw.info,meg=False,eeg=True,eog=False,stim=False)\n",
    "for sample in range(len(YLabel)):\n",
    "    startPoint=30*sample;endPoint=30*(sample+1)\n",
    "    start,stop=raw.time_as_index([startPoint,endPoint])\n",
    "    segment,time=raw[channel_index,start:stop]\n",
    "    for idx, channel_names in enumerate(channelList):\n",
    "        yf = 20*np.log10(np.abs(np.fft.rfft(segment[idx,:1000])))\n",
    "        validation_data[channel_names].append(yf)\n",
    "validation_data['label'].append(YLabel[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YLabel = label_binarize(windowLabel,classes=['2','3'])\n",
    "YLabel.sum(axis=0)/len(YLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clf = LogisticRegression(penalty='l1',C=0.5,tol=10e-10,fit_intercept=True,solver='liblinear',max_iter=1000,multi_class='ovr',\n",
    "#                        n_jobs=-1)\n",
    "clf = OneVsRestClassifier(SVC(kernel='linear',probability=True,random_state=101))\n",
    "weight_30s = {};y_pred={};cnt=1\n",
    "for channel_name in channelList:\n",
    "    \n",
    "    clf.fit(train_data[channel_name],train_data['label'])\n",
    "    weight_30s[channel_name]=clf\n",
    "    y_pred[channel_name]=clf.decision_function(validation_data[channel_name])\n",
    "    precision={};recall={};average_precision={}\n",
    "    for i in range(len(train_data['label'])+len(validation_data['label'])):\n",
    "        precision[i],recall[i],_=precision_recall_curve(validation_data['label'],)\n",
    "    print(channel_name,classification_report(validation_data['label'],y_pred[channel_name]))\n",
    "    print(channel_name,accuracy_score(validation_data['label'],y_pred[channel_name],normalize=False)/len(validation_data['label']))\n",
    "    print(channel_name,np.array(validation_data['label']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_number = 0\n",
    "channelList=['F3','F4','C3','C4','O1','O2','ROC','LOC']\n",
    "file_to_read,fileName = pick_sample_file(EDFfiles,n=sample_number)\n",
    "print(file_to_read)\n",
    "raw=load_data(file_to_read,channelList,5,50)\n",
    "channelList=['F3','F4','C3','C4','O1','O2']\n",
    "\n",
    "raw.pick_channels(channelList)\n",
    "\n",
    "file = annotation_file(TXTfiles,sample_number=sample_number)\n",
    "\n",
    "spindleFind = re.compile(\"spindle\", re.IGNORECASE)\n",
    "complexFind = re.compile(\"complex\",re.IGNORECASE)\n",
    "markPairs=[];dataLabels=[];eventCount=0;time=[]\n",
    "for row in file.iterrows():\n",
    "    currentEvent = row[1][-1]\n",
    "    if spindleFind.search(currentEvent):\n",
    "        time.append(row[1][0])\n",
    "    \n",
    "\n",
    "spindles={}\n",
    "for names in channelList:\n",
    "    spindles[names]=[]\n",
    "for moments in time:\n",
    "    segments = center_window_by_max_amplitude(raw,moments,channelList,windowsWidth=2.0)\n",
    "    for names in channelList:\n",
    "        spindles[names].append(segments[names])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ii,names in enumerate(channelList):\n",
    "    plt.subplot(3,2,ii+1)\n",
    "    plt.title(names)\n",
    "    for idx in range(len(data[names])):\n",
    "        \n",
    "        plt.plot(data[names][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample=-1\n",
    "for ii in range(6):\n",
    "    startPoint=time[sample]-2;endPoint=time[sample]+2\n",
    "    start,stop=raw.time_as_index([startPoint,endPoint])\n",
    "    tempsegment,timespan=raw[:,start:stop]\n",
    "    centerxval = timespan[np.argmax(abs(tempsegment[ii,:]))]\n",
    "    startPoint=centerxval-1;endPoint=centerxval+1\n",
    "    start,stop=raw.time_as_index([startPoint,endPoint])\n",
    "    segment,_=raw[:,start:stop]\n",
    "    plt.subplot(221)\n",
    "    normalized_segment=(segment[ii,:]-np.mean(segment[ii,:]))/scipy.linalg.norm(segment[ii,:])\n",
    "    plt.plot(range(len(normalized_segment)),normalized_segment)\n",
    "    plt.subplot(222)\n",
    "    yf = fft(normalized_segment)[:50]\n",
    "    plt.plot(np.fft.fftfreq(len(yf),np.abs(yf)))\n",
    "    \n",
    "    startPoint=time[sample+1]-2;endPoint=time[sample+1]+2\n",
    "    start,stop=raw.time_as_index([startPoint,endPoint])\n",
    "    tempsegment,timespan=raw[:,start:stop]\n",
    "    centerxval = timespan[np.argmax(abs(tempsegment[ii,:]))]\n",
    "    startPoint=centerxval-0.75;endPoint=centerxval+0.75\n",
    "    start,stop=raw.time_as_index([startPoint,endPoint])\n",
    "    segment,_=raw[:,start:stop]\n",
    "    plt.subplot(223)\n",
    "    normalized_segment=(segment[ii,:]-np.mean(segment[ii,:]))/scipy.linalg.norm(segment[ii,:])\n",
    "    plt.plot(range(len(normalized_segment)),normalized_segment)\n",
    "    plt.subplot(224)\n",
    "    yf = fft(normalized_segment)[:50]\n",
    "    plt.plot(np.fft.fftfreq(len(yf),np.abs(yf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "        if (spindleFind.search(curEvent) or complexFind.search(curEvent)):\n",
    "            time = row[1][0]\n",
    "            startTime = int(time - (duration*proprotion))\n",
    "            endTime = int(time + (duration*(1-proprotion)))\n",
    "            markPairs.append([startTime, endTime])\n",
    "            if spindleFind.search(curEvent):\n",
    "                dataLabels.append(0)\n",
    "            if complexFind.search(curEvent):\n",
    "                dataLabels.append(1)\n",
    "            eventCount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from numpy import NaN, Inf, arange, isscalar, asarray, array\n",
    "\n",
    "def peakdet(v, delta, x = None):\n",
    "    \"\"\"\n",
    "    Converted from MATLAB script at http://billauer.co.il/peakdet.html\n",
    "    \n",
    "    Returns two arrays\n",
    "    \n",
    "    function [maxtab, mintab]=peakdet(v, delta, x)\n",
    "    %PEAKDET Detect peaks in a vector\n",
    "    %        [MAXTAB, MINTAB] = PEAKDET(V, DELTA) finds the local\n",
    "    %        maxima and minima (\"peaks\") in the vector V.\n",
    "    %        MAXTAB and MINTAB consists of two columns. Column 1\n",
    "    %        contains indices in V, and column 2 the found values.\n",
    "    %      \n",
    "    %        With [MAXTAB, MINTAB] = PEAKDET(V, DELTA, X) the indices\n",
    "    %        in MAXTAB and MINTAB are replaced with the corresponding\n",
    "    %        X-values.\n",
    "    %\n",
    "    %        A point is considered a maximum peak if it has the maximal\n",
    "    %        value, and was preceded (to the left) by a value lower by\n",
    "    %        DELTA.\n",
    "    \n",
    "    % Eli Billauer, 3.4.05 (Explicitly not copyrighted).\n",
    "    % This function is released to the public domain; Any use is allowed.\n",
    "    \n",
    "    \"\"\"\n",
    "    maxtab = []\n",
    "    mintab = []\n",
    "       \n",
    "    if x is None:\n",
    "        x = arange(len(v))\n",
    "    \n",
    "    v = asarray(v)\n",
    "    \n",
    "    if len(v) != len(x):\n",
    "        sys.exit('Input vectors v and x must have same length')\n",
    "    \n",
    "    if not isscalar(delta):\n",
    "        sys.exit('Input argument delta must be a scalar')\n",
    "    \n",
    "    if delta <= 0:\n",
    "        sys.exit('Input argument delta must be positive')\n",
    "    \n",
    "    mn, mx = Inf, -Inf\n",
    "    mnpos, mxpos = NaN, NaN\n",
    "    \n",
    "    lookformax = True\n",
    "    \n",
    "    for i in arange(len(v)):\n",
    "        this = v[i];#print(this)\n",
    "        if this > mx:\n",
    "            mx = this\n",
    "            mxpos = x[i]\n",
    "        if this < mn:\n",
    "            mn = this\n",
    "            mnpos = x[i]\n",
    "        \n",
    "        if lookformax:\n",
    "            if this < mx-delta:\n",
    "                maxtab.append((mxpos, mx))\n",
    "                mn = this\n",
    "                mnpos = x[i]\n",
    "                lookformax = False\n",
    "        else:\n",
    "            if this > mn+delta:\n",
    "                mintab.append((mnpos, mn))\n",
    "                mx = this\n",
    "                mxpos = x[i]\n",
    "                lookformax = True\n",
    "\n",
    "    return array(maxtab), array(mintab)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    from matplotlib.pyplot import plot, scatter, show\n",
    "    fs = 1000 # sample rate \n",
    "    f = 20 # the frequency of the signal\n",
    "    x = np.arange(fs)\n",
    "    y = [ np.sin(2*np.pi*f * (i/fs)) for i in np.arange(fs)]+[ np.tan(2*np.pi*(f+5 )* (i/fs)) for i in np.arange(fs)]\n",
    "    series = y\n",
    "    maxtab, mintab = peakdet(series,1);print(maxtab.shape,mintab.shape)\n",
    "    plot(series)\n",
    "    scatter(array(maxtab)[:,0], array(maxtab)[:,1], color='blue')\n",
    "    scatter(array(mintab)[:,0], array(mintab)[:,1], color='red')\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suj10_d1final.edf\n",
      "Extracting edf Parameters from suj10_d1final.edf...\n",
      "Setting channel info structure...\n",
      "Creating Raw.info structure...\n",
      "Reading 0 ... 3601999  =      0.000 ...  3601.999 secs...\n",
      "[done]\n",
      "Ready.\n",
      "Band-pass filtering from 8 - 22 Hz\n",
      "Fitting ICA to data using 8 channels. \n",
      "Please be patient, this may take some time\n",
      "Inferring max_pca_components from picks.\n",
      "Using all PCA components: 8\n",
      "    Searching for artifacts...\n",
      "    found 2 artifacts by EOG 00\n",
      "    found 1 artifact by skewness\n",
      "    found 1 artifact by kurtosis\n",
      "    found 1 artifact by variance\n",
      "Artifact indices found:\n",
      "    6, 7, 7, 6, 3\n",
      "    Removing duplicate indices...\n",
      "Ready.\n",
      "Transforming to ICA space (8 components)\n",
      "Zeroing out 3 ICA components\n",
      "Inverse transforming to PCA space\n",
      "Reconstructing sensor space signals from 8 PCA components\n"
     ]
    }
   ],
   "source": [
    "channelList=['F3','F4','C3','C4','O1','O2','ROC','LOC']\n",
    "file_to_read,fileName = pick_sample_file(EDFfiles,n=2)\n",
    "print(file_to_read)\n",
    "#http://www.eurasip.org/Proceedings/Eusipco/Eusipco2005/defevent/papers/cr1847.pdf\n",
    "raw=load_data(file_to_read,channelList,8,22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_window=2\n",
    "distance_to_end = raw.last_samp/1000 - initial_window\n",
    "while distance_to_end >0:\n",
    "    window = initial_window\n",
    "    initial_window += 0.5\n",
    "    startPoint=window-2;endPoint=window\n",
    "    start,stop = raw.time_as_index([startPoint,endPoint])\n",
    "    segment,time = raw[0,start:stop]\n",
    "    mne.filter.band_pass_filter(segment,1000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ee0bc0e46ac5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minitial_window\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minitial_window\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0minitial_window\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "initial_window=[0,2]\n",
    "initial_window +=2\n",
    "initial_window"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
